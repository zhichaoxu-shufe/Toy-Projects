{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "two_layer network for regression.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOHcIizsePT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autograd.numpy as np\n",
        "import autograd.numpy.random as npr\n",
        "from autograd import grad\n",
        "import sklearn.metrics\n",
        "import pylab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQQ-fjAkeejZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate the Dataset\n",
        "examples = 1000\n",
        "features = 100\n",
        "D = (npr.randn(examples, features), npr.randn(examples))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlPXdvz4eeoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify the network\n",
        "layer1_units = 10\n",
        "layer2_units = 1\n",
        "w1 = npr.rand(features, layer1_units)\n",
        "b1 = npr.rand(layer1_units)\n",
        "w2 = npr.rand(layer1_units, layer2_units)\n",
        "b2 = 0.0\n",
        "theta = (w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYjxhi4SeerR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the loss function\n",
        "def squared_loss(y, y_hat):\n",
        "  return np.dot((y - y_hat), (y-y_hat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiXxdXv_fJI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output layer\n",
        "def binary_cross_entropy(y, y_hat):\n",
        "  return np.sum(-((y*np.log(y_hat)) + ((1-y) * np.log(1-y_hat))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y77iwkmafJLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wrapper around the neural network\n",
        "def neural_network(x, theta):\n",
        "  w1, b1, w2, b2 = theta\n",
        "  return np.tanh(np.dot((np.tanh(np.dot(x, w1)+b1)), w2) + b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gvALXHqfomy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wrapper around the objective function to be optimized\n",
        "def objective(theta, idx):\n",
        "  return squared_loss(D[1][idx], neural_network(D[0][idx], theta))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sV0JWCOf05s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# update\n",
        "def update_theta(theta, delta, alpha):\n",
        "  w1, b1, w2, b2 = theta\n",
        "  w1_delta, b1_delta, w2_delta, b2_delta = delta\n",
        "  w1_new = w1 - alpha*w1_delta\n",
        "  b1_new = b1 - alpha*b1_delta\n",
        "  w2_new = w2 - alpha*w2_delta\n",
        "  b2_new = b2 - alpha*b2_delta\n",
        "  new_theta = (w1_new, b1_new, w2_new, b2_new)\n",
        "  return new_theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPjpE9wlf0-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute gradient\n",
        "grad_objective = grad(objective)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYX-A7hFf1BL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "038b228f-4147-4ae7-b0e2-509343bd1bc8"
      },
      "source": [
        "# train the neural network\n",
        "epochs = 10\n",
        "print('RMSE before training: ', sklearn.metrics.mean_squared_error(D[1], neural_network(D[0], theta)))\n",
        "rmse = []\n",
        "for i in range(0, epochs):\n",
        "  for j in range(0, examples):\n",
        "    delta = grad_objective(theta, j)\n",
        "    theta = update_theta(theta, delta, 0.01)\n",
        "\n",
        "rmse.append(sklearn.metrics.mean_squared_error(D[1], neural_network(D[0], theta)))\n",
        "print('RMSE after training: ', sklearn.metrics.mean_squared_error(D[1], neural_network(D[0], theta)))\n",
        "print(rmse)\n",
        "\n",
        "pylab.plot(rmse)\n",
        "pylab.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE before training:  0.4709081100782502\n",
            "RMSE after training:  0.4230121763714401\n",
            "[0.4230121763714401]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRkEcmEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}