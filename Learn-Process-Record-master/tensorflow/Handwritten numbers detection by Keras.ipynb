{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"\"]).decode(\"utf8\"))\n",
    "\n",
    "# any results you write to the current directory are saved as output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and training & test sets, skipping the header row with [1:]\n",
    "train = pd.read_csv(\"\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (train.iloc[:, 1:].values).astype(\"float32\")\n",
    "# cast a dataframe object to specified data type\n",
    "\n",
    "# all pixel values\n",
    "y_train = train.iloc[:, 0].values.astype('int32')\n",
    "\n",
    "# only labels i.e target digits\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing the digit images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x):\n",
    "    return (x - mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utls import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(y_train[9])\n",
    "plt.plot(y_train[9])\n",
    "plt.xticks(range[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## designing neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 43\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Lambda, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization, Convolution2D, MaxPooling2D\n",
    "'''\n",
    "create a simple model from Keras Sequential layer\n",
    "\n",
    "1. lambda layer performs simple arithmetic operations like sum, average, exponentiation etc\n",
    "    In 1st layer performs simple arithmetic operations like sum, average, exponentiation etc\n",
    "2. flatten will transform input into 1D array\n",
    "3. dense is fully connected layer that means all neurons in previous layers will be connected to all neurons\n",
    "    in connected layer. In the last layer we have to specify output dimensions/classes of the model. \n",
    "    Here it is 10, since we have to output 10 different digit labels\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(standardize, input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"input shape\", model.input_shape)\n",
    "print(\"output shape\", model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "before making the network ready for training we have to make sure to add below things\n",
    "    1.a loss function: to measure how good the network is\n",
    "    2.an optimizer: to update network as it sees more data and reduce loss value\n",
    "    3.metrics: to monitor performance of network\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(optimizer = RMSprop(lr = 0.001), loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = X_train\n",
    "y = y_train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches=gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3,\n",
    "                             validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo')\n",
    "\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo')\n",
    "plt.plot(epochs, val_acc_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "s\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fully connected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neurons is a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks. Adding another Dense layer to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([Lambda(standardize, input_shape = (28, 28, 1)),\n",
    "                       Flatten(),\n",
    "                       Dense(512, activation='relu'),\n",
    "                       Dense(10, activation='softmax')\n",
    "                       ])\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = get_fc_model()\n",
    "fc.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fc.fit_generator(generator=batches,\n",
    "                          steps_per_epoch=batches.n,\n",
    "                          epochs=1,\n",
    "                          validation_data=val_batches,\n",
    "                          validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "def get_cnn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28, 28, 1)),\n",
    "        Convolution2D(32, (3, 3), activation='relu'),\n",
    "        Convolution2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64, (3, 3), activation='relu'),\n",
    "        Convolution2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model()\n",
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=batches, steps_per_epoch=batches.n,\n",
    "                             epochs=1,\n",
    "                             validation_data=val_batches,\n",
    "                             validation_steps=val_batches.n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "it is technique of showing slightly different of new images to neural network to avoid overfitting.\n",
    "and to achieve better generalization.\n",
    "in case you have very small dataset, you can use different kinds of data augmentation techiniques to\n",
    "increase your data size.\n",
    "neural networks perform better if you provide them with more data\n",
    "different data augmentation techniques are as follows:\n",
    "1.cropping\n",
    "2.rotating\n",
    "3.scaling\n",
    "4.translating\n",
    "5.flipping\n",
    "6.adding gaussian noise to input images etc.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN helps to fine tune hyperparameters move better and train really deep neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def get_bn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= get_bn_model()\n",
    "model.optimizer.lr=0.01\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
