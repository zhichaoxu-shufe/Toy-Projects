{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNLM tutorial.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "joAlj8V1BIP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl6Iqm-gCTQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "\n",
        "sentences = ['i like dog', 'i love coffee', 'i hate milk']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PjfAdnFCe9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_list = ' '.join(sentences).split()\n",
        "word_list = list(set(word_list))\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "number_dict = {i: w for i, w in enumerate(word_list)}\n",
        "\n",
        "n_class = len(word_dict)\n",
        "# number of vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOLt3h_QC8Xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NNLM parameter\n",
        "n_step = 2\n",
        "n_hidden = 2\n",
        "m = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSDq-dhBC8bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_batch(sentences):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    \n",
        "    for sen in sentences:\n",
        "        word = sen.split()\n",
        "        input = [word_dict[n] for n in word[:-1]]\n",
        "        target = word_dict[word[-1]]\n",
        "        \n",
        "        input_batch.append(input)\n",
        "        target_batch.append(target)\n",
        "    return input_batch, target_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaJotzLVC8ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "class NNLM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NNLM, self).__init__()\n",
        "        self.C = nn.Embedding(n_class, m)\n",
        "        self.H = nn.Parameter(torch.randn(n_step * m, n_hidden).type(dtype))\n",
        "        self.W = nn.Parameter(torch.randn(n_step * m, n_class).type(dtype))\n",
        "        self.d = nn.Parameter(torch.randn(n_hidden).type(dtype))\n",
        "        self.U = nn.Parameter(torch.randn(n_hidden, n_class).type(dtype))\n",
        "        self.b = nn.Parameter(torch.randn(n_class).type(dtype))\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = self.C(X)\n",
        "        X = X.view(-1, n_step * m)\n",
        "        # [batch_size, n_step * n_class]\n",
        "        tanh = torch.tanh(self.d + torch.mm(X, self.H))\n",
        "        # [batch_size, n_hidden]\n",
        "        output = self.b + torch.mm(X, self.W) + torch.mm(tanh, self.U)\n",
        "        # [batch_size, n_class]\n",
        "        return output\n",
        "\n",
        "    \n",
        "model = NNLM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYUQw0s6C8jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "input_batch, target_batch = make_batch(sentences)\n",
        "input_batch = Variable(torch.LongTensor(input_batch))\n",
        "target_batch = Variable(torch.LongTensor(target_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_38Z6sHJa-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "26a80ab9-f075-4ade-be47-1c6699c931b7"
      },
      "source": [
        "# training\n",
        "for epoch in range(5000):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_batch)\n",
        "    \n",
        "    # output: [batch_size, n_class], target_batch: [batch_size] (LongTensor, not one-hot)\n",
        "    loss = criterion(output, target_batch)\n",
        "    if (epoch+1)%100 == 0:\n",
        "        print('Epoch: ', \"%04d\" % (epoch+1), 'cost = ', '{:.6f}'.format(loss))\n",
        "        \n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0100 cost =  2.450696\n",
            "Epoch:  0200 cost =  1.583535\n",
            "Epoch:  0300 cost =  1.025847\n",
            "Epoch:  0400 cost =  0.651667\n",
            "Epoch:  0500 cost =  0.428014\n",
            "Epoch:  0600 cost =  0.295713\n",
            "Epoch:  0700 cost =  0.213091\n",
            "Epoch:  0800 cost =  0.158796\n",
            "Epoch:  0900 cost =  0.121646\n",
            "Epoch:  1000 cost =  0.095377\n",
            "Epoch:  1100 cost =  0.076273\n",
            "Epoch:  1200 cost =  0.062041\n",
            "Epoch:  1300 cost =  0.051208\n",
            "Epoch:  1400 cost =  0.042807\n",
            "Epoch:  1500 cost =  0.036182\n",
            "Epoch:  1600 cost =  0.030879\n",
            "Epoch:  1700 cost =  0.026577\n",
            "Epoch:  1800 cost =  0.023046\n",
            "Epoch:  1900 cost =  0.020115\n",
            "Epoch:  2000 cost =  0.017659\n",
            "Epoch:  2100 cost =  0.015582\n",
            "Epoch:  2200 cost =  0.013811\n",
            "Epoch:  2300 cost =  0.012288\n",
            "Epoch:  2400 cost =  0.010970\n",
            "Epoch:  2500 cost =  0.009819\n",
            "Epoch:  2600 cost =  0.008808\n",
            "Epoch:  2700 cost =  0.007912\n",
            "Epoch:  2800 cost =  0.007112\n",
            "Epoch:  2900 cost =  0.006394\n",
            "Epoch:  3000 cost =  0.005746\n",
            "Epoch:  3100 cost =  0.005160\n",
            "Epoch:  3200 cost =  0.004636\n",
            "Epoch:  3300 cost =  0.004173\n",
            "Epoch:  3400 cost =  0.003770\n",
            "Epoch:  3500 cost =  0.003421\n",
            "Epoch:  3600 cost =  0.003119\n",
            "Epoch:  3700 cost =  0.002855\n",
            "Epoch:  3800 cost =  0.002621\n",
            "Epoch:  3900 cost =  0.002413\n",
            "Epoch:  4000 cost =  0.002227\n",
            "Epoch:  4100 cost =  0.002059\n",
            "Epoch:  4200 cost =  0.001907\n",
            "Epoch:  4300 cost =  0.001769\n",
            "Epoch:  4400 cost =  0.001643\n",
            "Epoch:  4500 cost =  0.001529\n",
            "Epoch:  4600 cost =  0.001424\n",
            "Epoch:  4700 cost =  0.001327\n",
            "Epoch:  4800 cost =  0.001239\n",
            "Epoch:  4900 cost =  0.001157\n",
            "Epoch:  5000 cost =  0.001082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4WO5pk7JbBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict\n",
        "predict = model(input_batch).data.max(1, keepdim=True)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I2gco3YJbEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1ca10040-0905-4720-9354-ef913472e131"
      },
      "source": [
        "predict"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [0],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p4G_eVUKPV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c4265f8-d4c8-4891-ed3d-0335e685be79"
      },
      "source": [
        "# Test\n",
        "print([sen.split()[:2] for sen in sentences], '->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['i', 'like'], ['i', 'love'], ['i', 'hate']] -> ['dog', 'coffee', 'milk']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}