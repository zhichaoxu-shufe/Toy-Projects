{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I plan to build a 5-layers Sequential Convolutional Neural Network model. This model will be implemented by Keras API with Tensorflow as backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In addition, I trained an ensemble model. This idea comes from voting. When you apply several CNN models, the classification result is clearly better than the single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization, to see the classification problem is whether balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# drop 'label' column\n",
    "X_train = train.drop(labels=[\"label\"], axis=1)\n",
    "\n",
    "# free some space\n",
    "del train\n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null and missing values\n",
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape image in 3 dimensions(height=28px. width=28px, canal=1)\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test images have been stored in pandas.Dataframe as 1D vector of 784 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels to one hot vectors\n",
    "Y_train = to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "random_seed=2\n",
    "\n",
    "# split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This CNN model is classical CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv layer and BatchNormalization layer crossover, BatchNormalization helps reduces the probability of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the dropout layer is essential step, it helps simulate the sampling method, thus to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size=3, activation='relu', input_shape = (28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32, strides = 2, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the train parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We used the simulated annealing method ato decide the learning rate. Simulated annealing is classical numerical optimization method. Its performance is generally better than simply assign a static learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-09, decay=0.0)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "epochs = 45\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this step, we used distortion idea to simulate more training data. Its performance is excellent. Not only do we increase the size of the training set, but also our neural network has better generalization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 7s - loss: 0.4204 - acc: 0.8702 - val_loss: 0.0727 - val_acc: 0.9795\n",
      "Epoch 2/30\n",
      " - 6s - loss: 0.1174 - acc: 0.9642 - val_loss: 0.0633 - val_acc: 0.9829\n",
      "Epoch 3/30\n",
      " - 6s - loss: 0.0931 - acc: 0.9725 - val_loss: 0.0442 - val_acc: 0.9879\n",
      "Epoch 4/30\n",
      " - 6s - loss: 0.0727 - acc: 0.9783 - val_loss: 0.0363 - val_acc: 0.9883\n",
      "Epoch 5/30\n",
      " - 6s - loss: 0.0691 - acc: 0.9787 - val_loss: 0.0233 - val_acc: 0.9924\n",
      "Epoch 6/30\n",
      " - 6s - loss: 0.0612 - acc: 0.9820 - val_loss: 0.0384 - val_acc: 0.9910\n",
      "Epoch 7/30\n",
      " - 7s - loss: 0.0604 - acc: 0.9821 - val_loss: 0.0213 - val_acc: 0.9931\n",
      "Epoch 8/30\n",
      " - 6s - loss: 0.0534 - acc: 0.9843 - val_loss: 0.0235 - val_acc: 0.9924\n",
      "Epoch 9/30\n",
      " - 6s - loss: 0.0511 - acc: 0.9848 - val_loss: 0.0272 - val_acc: 0.9919\n",
      "Epoch 10/30\n",
      " - 6s - loss: 0.0488 - acc: 0.9860 - val_loss: 0.0230 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/30\n",
      " - 7s - loss: 0.0387 - acc: 0.9884 - val_loss: 0.0201 - val_acc: 0.9945\n",
      "Epoch 12/30\n",
      " - 6s - loss: 0.0367 - acc: 0.9890 - val_loss: 0.0153 - val_acc: 0.9955\n",
      "Epoch 13/30\n",
      " - 6s - loss: 0.0334 - acc: 0.9900 - val_loss: 0.0171 - val_acc: 0.9945\n",
      "Epoch 14/30\n",
      " - 6s - loss: 0.0330 - acc: 0.9903 - val_loss: 0.0195 - val_acc: 0.9950\n",
      "Epoch 15/30\n",
      " - 7s - loss: 0.0328 - acc: 0.9903 - val_loss: 0.0152 - val_acc: 0.9957\n",
      "Epoch 16/30\n",
      " - 6s - loss: 0.0302 - acc: 0.9906 - val_loss: 0.0182 - val_acc: 0.9950\n",
      "Epoch 17/30\n",
      " - 6s - loss: 0.0312 - acc: 0.9909 - val_loss: 0.0145 - val_acc: 0.9955\n",
      "Epoch 18/30\n",
      " - 6s - loss: 0.0302 - acc: 0.9914 - val_loss: 0.0144 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/30\n",
      " - 7s - loss: 0.0256 - acc: 0.9918 - val_loss: 0.0171 - val_acc: 0.9960\n",
      "Epoch 20/30\n",
      " - 6s - loss: 0.0239 - acc: 0.9931 - val_loss: 0.0140 - val_acc: 0.9960\n",
      "Epoch 21/30\n",
      " - 6s - loss: 0.0221 - acc: 0.9931 - val_loss: 0.0136 - val_acc: 0.9962\n",
      "Epoch 22/30\n",
      " - 6s - loss: 0.0231 - acc: 0.9934 - val_loss: 0.0168 - val_acc: 0.9967\n",
      "Epoch 23/30\n",
      " - 6s - loss: 0.0240 - acc: 0.9928 - val_loss: 0.0140 - val_acc: 0.9962\n",
      "Epoch 24/30\n",
      " - 7s - loss: 0.0240 - acc: 0.9931 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 25/30\n",
      " - 7s - loss: 0.0238 - acc: 0.9932 - val_loss: 0.0147 - val_acc: 0.9957\n",
      "Epoch 26/30\n",
      " - 6s - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0185 - val_acc: 0.9955\n",
      "Epoch 27/30\n",
      " - 6s - loss: 0.0236 - acc: 0.9930 - val_loss: 0.0130 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 28/30\n",
      " - 6s - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0140 - val_acc: 0.9962\n",
      "Epoch 29/30\n",
      " - 6s - loss: 0.0212 - acc: 0.9940 - val_loss: 0.0175 - val_acc: 0.9960\n",
      "Epoch 30/30\n",
      " - 6s - loss: 0.0204 - acc: 0.9941 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = 30, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This performance is 0.99700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try ensemble method, ensemble 15 CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = 15\n",
    "model = [0]*nets\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "    \n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=10,\n",
    "                        zoom_range=0.10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 1: Epochs=20, Train accuracy=0.99635, Validation accuracy=0.99841\n",
      "CNN 2: Epochs=20, Train accuracy=0.99685, Validation accuracy=0.99656\n",
      "CNN 3: Epochs=20, Train accuracy=0.99614, Validation accuracy=0.99894\n",
      "CNN 4: Epochs=20, Train accuracy=0.99658, Validation accuracy=0.99815\n",
      "CNN 5: Epochs=20, Train accuracy=0.99673, Validation accuracy=0.99735\n",
      "CNN 6: Epochs=20, Train accuracy=0.99682, Validation accuracy=0.99788\n",
      "CNN 7: Epochs=20, Train accuracy=0.99635, Validation accuracy=0.99762\n",
      "CNN 8: Epochs=20, Train accuracy=0.99647, Validation accuracy=0.99868\n",
      "CNN 9: Epochs=20, Train accuracy=0.99552, Validation accuracy=0.99762\n",
      "CNN 10: Epochs=20, Train accuracy=0.99491, Validation accuracy=0.99656\n",
      "CNN 11: Epochs=20, Train accuracy=0.99499, Validation accuracy=0.99709\n",
      "CNN 12: Epochs=20, Train accuracy=0.99479, Validation accuracy=0.99735\n",
      "CNN 13: Epochs=20, Train accuracy=0.99462, Validation accuracy=0.99762\n",
      "CNN 14: Epochs=20, Train accuracy=0.99476, Validation accuracy=0.99762\n",
      "CNN 15: Epochs=20, Train accuracy=0.99482, Validation accuracy=0.99709\n"
     ]
    }
   ],
   "source": [
    "# DECREASE LEARNING RATE EACH EPOCH\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "epochs = 20\n",
    "for j in range(nets):\n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n",
    "    history[j] = model[j].fit_generator(gen.flow(X_train2,Y_train2, batch_size=64),\n",
    "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
    "        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n",
    "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE PREDICTIONS AND SUBMIT\n",
    "results = np.zeros( (test.shape[0],10) ) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"MNIST-CNN-ENSEMBLE.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This performance is 0.99728 Best so far"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
